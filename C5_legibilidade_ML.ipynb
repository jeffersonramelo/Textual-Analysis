{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzW834yAe0u6O2cOtQr8+f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffersonramelo/Textual-Analysis/blob/main/C5_legibilidade_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ler o arquivo CSV\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/C456_ dataset legibilidade rotulados.csv\")"
      ],
      "metadata": {
        "id": "c2mDZfX7YWnV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vizualizar dados\n",
        "df"
      ],
      "metadata": {
        "id": "wqgE3so93YYp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ecaf5643-85b3-46b9-c4d8-ca8eec71a2bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          terms  \\\n",
              "0                     Low/No Documentation Loan   \n",
              "1     Combined Loan-To-Value Ratio (CLTV Ratio)   \n",
              "2                          Nonforfeiture Clause   \n",
              "3                        Discretionary spending   \n",
              "4                                DEBT TO ASSETS   \n",
              "...                                         ...   \n",
              "1495                        Sole Proprietorship   \n",
              "1496         UCLA Anderson School of Management   \n",
              "1497                               Unemployment   \n",
              "1498                          Pro Forma Invoice   \n",
              "1499                          full-payout lease   \n",
              "\n",
              "                                            definitions        source  \\\n",
              "0     A low/no documentation loan allows a potential...  investopedia   \n",
              "1     The combined loan-to-value (CLTV) ratio is the...  investopedia   \n",
              "2     A nonforfeiture (sometimes hyphenated) clause ...  investopedia   \n",
              "3     Government spending authorized by Congress on ...    9_12_louis   \n",
              "4     A measure of a company’s FINANCIAL LEVERAGE, o...      palgrave   \n",
              "...                                                 ...           ...   \n",
              "1495  A sole proprietorship also referred to as a so...  investopedia   \n",
              "1496  UCLA Anderson School of Management is the grad...  investopedia   \n",
              "1497  @1@ In economic terms,  involuntary unemployme...           sam   \n",
              "1498  A pro forma invoice is a preliminary bill of s...  investopedia   \n",
              "1499                                   financial lease.          prin   \n",
              "\n",
              "      assigned_readability  flesch_reading_ease  flesch_kincaid_grade  \\\n",
              "0                        1                22.75                  15.8   \n",
              "1                        1                45.77                  17.3   \n",
              "2                        1                29.18                  15.4   \n",
              "3                        1                28.50                  11.5   \n",
              "4                        0                45.46                  11.2   \n",
              "...                    ...                  ...                   ...   \n",
              "1495                     1                37.98                  16.2   \n",
              "1496                     1                41.70                  12.7   \n",
              "1497                     1                15.65                  18.5   \n",
              "1498                     1                58.62                  10.3   \n",
              "1499                     0                35.61                   8.8   \n",
              "\n",
              "      smog_index  coleman_liau_index  automated_readability_index  \\\n",
              "0            0.0               16.42                         17.8   \n",
              "1            0.0                9.01                         21.0   \n",
              "2           17.1               14.10                         16.9   \n",
              "3            0.0               15.11                         11.3   \n",
              "4           13.0               10.67                         11.1   \n",
              "...          ...                 ...                          ...   \n",
              "1495         0.0               11.79                         18.5   \n",
              "1496         0.0               12.30                         13.8   \n",
              "1497         0.0               10.28                         16.6   \n",
              "1498         0.0               11.60                         12.9   \n",
              "1499         0.0               10.00                         14.9   \n",
              "\n",
              "      dale_chall_readability_score  linsear_write_formula  gunning_fog  \n",
              "0                            11.99              18.000000        20.50  \n",
              "1                            10.23              12.500000        18.70  \n",
              "2                             9.93              18.500000        15.33  \n",
              "3                            12.86               6.500000        12.49  \n",
              "4                             9.96              11.666667        10.00  \n",
              "...                            ...                    ...          ...  \n",
              "1495                          9.10              20.500000        16.84  \n",
              "1496                          9.94              16.000000        16.97  \n",
              "1497                         11.70              20.500000        16.67  \n",
              "1498                         10.69              13.000000        12.21  \n",
              "1499                         19.53               1.000000        20.80  \n",
              "\n",
              "[1500 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45f2f8d2-7660-4a7c-bc77-54640eaaf9fe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>terms</th>\n",
              "      <th>definitions</th>\n",
              "      <th>source</th>\n",
              "      <th>assigned_readability</th>\n",
              "      <th>flesch_reading_ease</th>\n",
              "      <th>flesch_kincaid_grade</th>\n",
              "      <th>smog_index</th>\n",
              "      <th>coleman_liau_index</th>\n",
              "      <th>automated_readability_index</th>\n",
              "      <th>dale_chall_readability_score</th>\n",
              "      <th>linsear_write_formula</th>\n",
              "      <th>gunning_fog</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Low/No Documentation Loan</td>\n",
              "      <td>A low/no documentation loan allows a potential...</td>\n",
              "      <td>investopedia</td>\n",
              "      <td>1</td>\n",
              "      <td>22.75</td>\n",
              "      <td>15.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.42</td>\n",
              "      <td>17.8</td>\n",
              "      <td>11.99</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>20.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Combined Loan-To-Value Ratio (CLTV Ratio)</td>\n",
              "      <td>The combined loan-to-value (CLTV) ratio is the...</td>\n",
              "      <td>investopedia</td>\n",
              "      <td>1</td>\n",
              "      <td>45.77</td>\n",
              "      <td>17.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.01</td>\n",
              "      <td>21.0</td>\n",
              "      <td>10.23</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>18.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nonforfeiture Clause</td>\n",
              "      <td>A nonforfeiture (sometimes hyphenated) clause ...</td>\n",
              "      <td>investopedia</td>\n",
              "      <td>1</td>\n",
              "      <td>29.18</td>\n",
              "      <td>15.4</td>\n",
              "      <td>17.1</td>\n",
              "      <td>14.10</td>\n",
              "      <td>16.9</td>\n",
              "      <td>9.93</td>\n",
              "      <td>18.500000</td>\n",
              "      <td>15.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Discretionary spending</td>\n",
              "      <td>Government spending authorized by Congress on ...</td>\n",
              "      <td>9_12_louis</td>\n",
              "      <td>1</td>\n",
              "      <td>28.50</td>\n",
              "      <td>11.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.11</td>\n",
              "      <td>11.3</td>\n",
              "      <td>12.86</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>12.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DEBT TO ASSETS</td>\n",
              "      <td>A measure of a company’s FINANCIAL LEVERAGE, o...</td>\n",
              "      <td>palgrave</td>\n",
              "      <td>0</td>\n",
              "      <td>45.46</td>\n",
              "      <td>11.2</td>\n",
              "      <td>13.0</td>\n",
              "      <td>10.67</td>\n",
              "      <td>11.1</td>\n",
              "      <td>9.96</td>\n",
              "      <td>11.666667</td>\n",
              "      <td>10.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>Sole Proprietorship</td>\n",
              "      <td>A sole proprietorship also referred to as a so...</td>\n",
              "      <td>investopedia</td>\n",
              "      <td>1</td>\n",
              "      <td>37.98</td>\n",
              "      <td>16.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.79</td>\n",
              "      <td>18.5</td>\n",
              "      <td>9.10</td>\n",
              "      <td>20.500000</td>\n",
              "      <td>16.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>UCLA Anderson School of Management</td>\n",
              "      <td>UCLA Anderson School of Management is the grad...</td>\n",
              "      <td>investopedia</td>\n",
              "      <td>1</td>\n",
              "      <td>41.70</td>\n",
              "      <td>12.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.30</td>\n",
              "      <td>13.8</td>\n",
              "      <td>9.94</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>Unemployment</td>\n",
              "      <td>@1@ In economic terms,  involuntary unemployme...</td>\n",
              "      <td>sam</td>\n",
              "      <td>1</td>\n",
              "      <td>15.65</td>\n",
              "      <td>18.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.28</td>\n",
              "      <td>16.6</td>\n",
              "      <td>11.70</td>\n",
              "      <td>20.500000</td>\n",
              "      <td>16.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>Pro Forma Invoice</td>\n",
              "      <td>A pro forma invoice is a preliminary bill of s...</td>\n",
              "      <td>investopedia</td>\n",
              "      <td>1</td>\n",
              "      <td>58.62</td>\n",
              "      <td>10.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.60</td>\n",
              "      <td>12.9</td>\n",
              "      <td>10.69</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>12.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>full-payout lease</td>\n",
              "      <td>financial lease.</td>\n",
              "      <td>prin</td>\n",
              "      <td>0</td>\n",
              "      <td>35.61</td>\n",
              "      <td>8.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.00</td>\n",
              "      <td>14.9</td>\n",
              "      <td>19.53</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.80</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45f2f8d2-7660-4a7c-bc77-54640eaaf9fe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45f2f8d2-7660-4a7c-bc77-54640eaaf9fe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45f2f8d2-7660-4a7c-bc77-54640eaaf9fe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#quantos dados positivo e negativos?\n",
        "df.assigned_readability.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy90HFtf3Hzv",
        "outputId": "1d099de6-7d8c-4678-b281-2863b74fb9ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    874\n",
              "0    626\n",
              "Name: assigned_readability, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Acessar os definitionsitionss contidos nas celulas, só substituir o número da celula que deseja vizualizar\n",
        "celula = df.loc[0, 'definitions']\n",
        "\n",
        "# Imprimir o conteúdo da célula\n",
        "print(celula)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNLlKhMh35qO",
        "outputId": "82af0036-5b65-4ecf-f507-4b6b54b1fed0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A low/no documentation loan allows a potential borrower to apply for a mortgage while providing little or no information regarding their employment, income, or assets. Regulation of these loans has evolved significantly since 2008, but they remain an option for some borrowers in nontraditional financial situations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pre-processamento do definitions (stop words, misnusculas, caracteres especiais, stemização e tokenização)"
      ],
      "metadata": {
        "id": "TwiiGHcVccX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P7uAxFxvTPV",
        "outputId": "76a907ed-64ac-48f8-d189-015c3f9c6386"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes"
      ],
      "metadata": {
        "id": "FcplM6PyesNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Dividir o DataFrame em dados de treinamento e teste\n",
        "X = df['definitions']\n",
        "y = df['assigned_readability']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preencher valores nulos com uma string vazia\n",
        "imputer = SimpleImputer(strategy='constant', fill_value='')\n",
        "X_train = pd.DataFrame(X_train, columns=['definitions'])\n",
        "X_test = pd.DataFrame(X_test, columns=['definitions'])\n",
        "X_train['definitions'] = imputer.fit_transform(X_train[['definitions']])\n",
        "X_test['definitions'] = imputer.transform(X_test[['definitions']])\n",
        "\n",
        "# Pré-processamento dos dados de definitions\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train['definitions'])\n",
        "X_test = vectorizer.transform(X_test['definitions'])\n",
        "\n",
        "# Inicializar os classificadores\n",
        "mnb = MultinomialNB()\n",
        "gnb = GaussianNB()\n",
        "bnb = BernoulliNB()\n",
        "\n",
        "# Realizar validação cruzada nos classificadores\n",
        "cv_scores_mnb = cross_val_score(mnb, X_train, y_train, cv=5)\n",
        "cv_scores_gnb = cross_val_score(gnb, X_train.toarray(), y_train, cv=5)\n",
        "cv_scores_bnb = cross_val_score(bnb, X_train, y_train, cv=5)\n",
        "\n",
        "# Treinar os classificadores nos dados de treinamento completos\n",
        "mnb.fit(X_train, y_train)\n",
        "gnb.fit(X_train.toarray(), y_train)\n",
        "bnb.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsões nos dados de teste\n",
        "y_pred_mnb = mnb.predict(X_test)\n",
        "y_pred_gnb = gnb.predict(X_test.toarray())\n",
        "y_pred_bnb = bnb.predict(X_test)\n"
      ],
      "metadata": {
        "id": "SPwxAcFYeDXc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular a matriz de confusão\n",
        "confusion_mnb = confusion_matrix(y_test, y_pred_mnb)\n",
        "print(\"confusion_mnb\", confusion_mnb)\n",
        "confusion_gnb = confusion_matrix(y_test, y_pred_gnb)\n",
        "print(\"confusion_gnb\", confusion_gnb)\n",
        "confusion_bnb = confusion_matrix(y_test, y_pred_bnb)\n",
        "print(\"confusion_bnb\", confusion_bnb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7kUc7UYv4lU",
        "outputId": "6c91c796-4dc1-400f-a7d9-a4962741a630"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion_mnb [[ 97  32]\n",
            " [ 12 159]]\n",
            "confusion_gnb [[ 75  54]\n",
            " [ 22 149]]\n",
            "confusion_bnb [[121   8]\n",
            " [ 34 137]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliar o desempenho dos classificadores com a métrica de acurácia\n",
        "accuracy_mnb = accuracy_score(y_test, y_pred_mnb)\n",
        "print(\"accuracy_mnb\", accuracy_mnb)\n",
        "accuracy_gnb = accuracy_score(y_test, y_pred_gnb)\n",
        "print(\"accuracy_gnb\", accuracy_gnb)\n",
        "accuracy_bnb = accuracy_score(y_test, y_pred_bnb)\n",
        "print(\"accuracy_bnb\", accuracy_bnb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBCe0CFGvrsF",
        "outputId": "2eb06511-8475-41cf-a369-334ce23b4ab6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_mnb 0.8533333333333334\n",
            "accuracy_gnb 0.7466666666666667\n",
            "accuracy_bnb 0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suporte Vector Machine"
      ],
      "metadata": {
        "id": "tq7eIu4aeQ0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Dividir o DataFrame em dados de treinamento e teste\n",
        "X = df['definitions']\n",
        "y = df['assigned_readability']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Pré-processamento dos dados de definitions\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)\n",
        "\n",
        "# Inicializar o classificador SVM\n",
        "svm = SVC()\n",
        "\n",
        "# Treinar o classificador SVM\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsões nos dados de teste\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "\n",
        "# Gerar a matriz de confusão\n",
        "confusion_mtx_svm = confusion_matrix(y_test, y_pred_svm)\n",
        "\n",
        "print(\"Matriz de Confusão - SVM:\")\n",
        "print(confusion_mtx_svm)\n",
        "\n",
        "# Calcular a acurácia do modelo SVM\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "\n",
        "print(\"Acurácia - SVM:\", accuracy_svm)\n"
      ],
      "metadata": {
        "id": "eW1HYInhezbj",
        "outputId": "8fa94e66-223b-4341-ba58-80c39dded4a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Confusão - SVM:\n",
            "[[107  22]\n",
            " [ 27 144]]\n",
            "Acurácia - SVM: 0.8366666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Redes Neurais\n",
        "\n",
        "Perceptron de Múltiplas Camadas (Multilayer Perceptron, MLP). O MLP é uma arquitetura de rede neural artificial que consiste em várias camadas de neurônios, incluindo uma camada de entrada, uma ou mais camadas ocultas e uma camada de saída. Cada neurônio em uma camada está conectado a todos os neurônios na camada seguinte, formando uma rede densamente conectada."
      ],
      "metadata": {
        "id": "lhqBzsyQe9DX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Dividir o DataFrame em dados de treinamento e teste\n",
        "X = df['definitions']\n",
        "y = df['assigned_readability']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Pré-processamento dos dados de definitions\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)\n",
        "\n",
        "# Inicializar o classificador MLP\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), random_state=42)\n",
        "\n",
        "# Treinar o classificador MLP\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsões nos dados de teste\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "\n",
        "# Gerar a matriz de confusão\n",
        "confusion_mtx_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
        "\n",
        "print(\"Matriz de Confusão - MLP:\")\n",
        "print(confusion_mtx_mlp)\n",
        "\n",
        "# Calcular a acurácia do modelo MLP\n",
        "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
        "\n",
        "print(\"Acurácia - MLP:\", accuracy_mlp)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeSoVTuwe-4D",
        "outputId": "8e082a85-55d3-4a2b-9ff7-98e3eb3d5f6a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Confusão - MLP:\n",
            "[[109  20]\n",
            " [ 30 141]]\n",
            "Acurácia - MLP: 0.8333333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recurrent Neural Network (RNN): RNNs, em particular, as variantes como Long Short-Term Memory (LSTM) ou Gated Recurrent Unit (GRU), são amplamente utilizadas em análise textual. Essas arquiteturas são capazes de capturar dependências de contexto e sequenciais em texto, tornando-as adequadas para tarefas como classificação de sentimento, geração de texto ou tradução automática."
      ],
      "metadata": {
        "id": "cx6QEt2zQ9pF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import tensorflow as tf\n",
        "\n",
        "# Dividir o DataFrame em dados de treinamento e teste\n",
        "X = df['definitions']\n",
        "y = df['assigned_readability']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Pré-processamento dos dados de definitions\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train).toarray()\n",
        "X_test = vectorizer.transform(X_test).toarray()\n",
        "\n",
        "# Definir a arquitetura da RNN\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(vectorizer.vocabulary_), output_dim=100, input_length=X_train.shape[1]),\n",
        "    tf.keras.layers.SimpleRNN(units=64),\n",
        "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Treinar a RNN\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Fazer previsões nos dados de teste\n",
        "y_pred_rnn = model.predict(X_test)\n",
        "y_pred_rnn = (y_pred_rnn > 0.5).astype(int)\n",
        "\n",
        "# Gerar a matriz de confusão\n",
        "confusion_mtx_rnn = confusion_matrix(y_test, y_pred_rnn)\n",
        "\n",
        "print(\"Matriz de Confusão - RNN:\")\n",
        "print(confusion_mtx_rnn)\n",
        "\n",
        "# Calcular a acurácia do modelo RNN\n",
        "accuracy_rnn = accuracy_score(y_test, y_pred_rnn)\n",
        "\n",
        "print(\"Acurácia - RNN:\", accuracy_rnn)\n"
      ],
      "metadata": {
        "id": "UP6yvBDxQ6U2",
        "outputId": "758b51a2-462d-4ba0-c23f-33e83ecbe3d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 5/38 [==>...........................] - ETA: 3:47 - loss: 0.6711 - accuracy: 0.6438"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional Neural Network (CNN): Embora inicialmente desenvolvidas para processamento de imagens, as CNNs também podem ser aplicadas a análise textual, especialmente em tarefas como classificação de texto ou extração de características. As camadas convolucionais nas CNNs são capazes de extrair informações relevantes de n-gramas de palavras, capturando padrões locais em textos."
      ],
      "metadata": {
        "id": "otOpT_NHRMl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import tensorflow as tf\n",
        "\n",
        "# Dividir o DataFrame em dados de treinamento e teste\n",
        "X = df['definitions']\n",
        "y = df['assigned_readability']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Pré-processamento dos dados de definitions\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train).toarray()\n",
        "X_test = vectorizer.transform(X_test).toarray()\n",
        "\n",
        "# Redimensionar os dados para a entrada da CNN (adicionar uma dimensão de canal)\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "X_test = np.expand_dims(X_test, axis=-1)\n",
        "\n",
        "# Definir a arquitetura da CNN\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Treinar a CNN\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Fazer previsões nos dados de teste\n",
        "y_pred_cnn = model.predict(X_test)\n",
        "y_pred_cnn = (y_pred_cnn > 0.5).astype(int)\n",
        "\n",
        "# Gerar a matriz de confusão\n",
        "confusion_mtx_cnn = confusion_matrix(y_test, y_pred_cnn)\n",
        "\n",
        "print(\"Matriz de Confusão - CNN:\")\n",
        "print(confusion_mtx_cnn)\n",
        "\n",
        "# Calcular a acurácia do modelo CNN\n",
        "accuracy_cnn = accuracy_score(y_test, y_pred_cnn)\n",
        "\n",
        "print(\"Acurácia - CNN:\", accuracy_cnn)\n"
      ],
      "metadata": {
        "id": "o08iH2RlRP09"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}