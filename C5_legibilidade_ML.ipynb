{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzW834yAe0u6O2cOtQr8+f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffersonramelo/Textual-Analysis/blob/main/C5_legibilidade_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ler o arquivo CSV\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/C456_ dataset legibilidade rotulados.csv\")"
      ],
      "metadata": {
        "id": "c2mDZfX7YWnV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vizualizar dados\n",
        "df"
      ],
      "metadata": {
        "id": "wqgE3so93YYp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ecaf5643-85b3-46b9-c4d8-ca8eec71a2bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          terms  \\\n",
              "0                     Low/No Documentation Loan   \n",
              "1     Combined Loan-To-Value Ratio (CLTV Ratio)   \n",
              "2                          Nonforfeiture Clause   \n",
              "3                        Discretionary spending   \n",
              "4                                DEBT TO ASSETS   \n",
              "...                                         ...   \n",
              "1495                        Sole Proprietorship   \n",
              "1496         UCLA Anderson School of Management   \n",
              "1497                               Unemployment   \n",
              "1498                          Pro Forma Invoice   \n",
              "1499                          full-payout lease   \n",
              "\n",
              "                                            definitions        source  \\\n",
              "0     A low/no documentation loan allows a potential...  investopedia   \n",
              "1     The combined loan-to-value (CLTV) ratio is the...  investopedia   \n",
              "2     A nonforfeiture (sometimes hyphenated) clause ...  investopedia   \n",
              "3     Government spending authorized by Congress on ...    9_12_louis   \n",
              "4     A measure of a companyâ€™s FINANCIAL LEVERAGE, o...      palgrave   \n",
              "...                                                 ...           ...   \n",
              "1495  A sole proprietorship also referred to as a so...  investopedia   \n",
              "1496  UCLA Anderson School of Management is the grad...  investopedia   \n",
              "1497  @1@ In economic terms,  involuntary unemployme...           sam   \n",
              "1498  A pro forma invoice is a preliminary bill of s...  investopedia   \n",
              "1499                                   financial lease.          prin   \n",
              "\n",
              "      assigned_readability  flesch_reading_ease  flesch_kincaid_grade  \\\n",
              "0                        1                22.75                  15.8   \n",
              "1                        1                45.77                  17.3   \n",
              "2                        1                29.18                  15.4   \n",
              "3                        1                28.50                  11.5   \n",
              "4                        0                45.46                  11.2   \n",
              "...                    ...                  ...                   ...   \n",
              "1495                     1                37.98                  16.2   \n",
              "1496                     1                41.70                  12.7   \n",
              "1497                     1                15.65                  18.5   \n",
              "1498                     1                58.62                  10.3   \n",
              "1499                     0                35.61                   8.8   \n",
              "\n",
              "      smog_index  coleman_liau_index  automated_readability_index  \\\n",
              "0            0.0               16.42                         17.8   \n",
              "1            0.0                9.01                         21.0   \n",
              "2           17.1               14.10                         16.9   \n",
              "3            0.0               15.11                         11.3   \n",
              "4           13.0               10.67                         11.1   \n",
              "...          ...                 ...                          ...   \n",
              "1495         0.0               11.79                         18.5   \n",
              "1496         0.0               12.30                         13.8   \n",
              "1497         0.0               10.28                         16.6   \n",
              "1498         0.0               11.60                         12.9   \n",
              "1499         0.0               10.00                         14.9   \n",
              "\n",
              "      dale_chall_readability_score  linsear_write_formula  gunning_fog  \n",
              "0                            11.99              18.000000        20.50  \n",
              "1                            10.23              12.500000        18.70  \n",
              "2                             9.93              18.500000        15.33  \n",
              "3                            12.86               6.500000        12.49  \n",
              "4                             9.96              11.666667        10.00  \n",
              "...                            ...                    ...          ...  \n",
              "1495                          9.10              20.500000        16.84  \n",
              "1496                          9.94              16.000000        16.97  \n",
              "1497                         11.70              20.500000        16.67  \n",
              "1498                         10.69              13.000000        12.21  \n",
              "1499                         19.53               1.000000        20.80  \n",
              "\n",
              "[1500 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45f2f8d2-7660-4a7c-bc77-54640eaaf9fe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>terms</th>\n",
              "      <th>definitions</th>\n",
              "      <th>source</th>\n",
              "      <th>assigned_readability</th>\n",
              "      <th>flesch_reading_ease</th>\n",
              "      <th>flesch_kincaid_grade</th>\n",
              "      <th>smog_index</th>\n",
              "      <th>coleman_liau_index</th>\n",
              "      <th>automated_readability_index</th>\n",
              "      <th>dale_chall_readability_score</th>\n",
              "      <th>linsear_write_formula</th>\n",
              "      <th>gunning_fog</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Low/No Documentation Loan</td>\n",
              "      <td>A low/no documentation loan allows a potential...</td>\n",
              "      <td>investopedia</td>\n",
              "      <td>1</td>\n",
              "      <td>22.75</td>\n",
              "      <td>15.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.42</td>\n",
              "      <td>17.8</td>\n",
              "      <td>11.99</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>20.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Combined Loan-To-Value Ratio (CLTV Ratio)</td>\n",
              "      <td>The combined loan-to-value (CLTV) ratio is the...</td>\n",
              "      <td>investopedia</td>\n",
              "      <td>1</td>\n",
              "      <td>45.77</td>\n",
              "      <td>17.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.01</td>\n",
              "      <td>21.0</td>\n",
              "      <td>10.23</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>18.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nonforfeiture Clause</td>\n",
              "      <td>A nonforfeiture (sometimes hyphenated) clause ...</td>\n",
              "      <td>investopedia</td>\n",
              "      <td>1</td>\n",
              "      <td>29.18</td>\n",
              "      <td>15.4</td>\n",
              "      <td>17.1</td>\n",
              "      <td>14.10</td>\n",
              "      <td>16.9</td>\n",
              "      <td>9.93</td>\n",
              "      <td>18.500000</td>\n",
              "      <td>15.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Discretionary spending</td>\n",
              "      <td>Government spending authorized by Congress on ...</td>\n",
              "      <td>9_12_louis</td>\n",
              "      <td>1</td>\n",
              "      <td>28.50</td>\n",
              "      <td>11.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.11</td>\n",
              "      <td>11.3</td>\n",
              "      <td>12.86</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>12.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DEBT TO ASSETS</td>\n",
              "      <td>A measure of a companyâ€™s FINANCIAL LEVERAGE, o...</td>\n",
              "      <td>palgrave</td>\n",
              "      <td>0</td>\n",
              "      <td>45.46</td>\n",
              "      <td>11.2</td>\n",
              "      <td>13.0</td>\n",
              "      <td>10.67</td>\n",
              "      <td>11.1</td>\n",
              "      <td>9.96</td>\n",
              "      <td>11.666667</td>\n",
              "      <td>10.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>Sole Proprietorship</td>\n",
              "      <td>A sole proprietorship also referred to as a so...</td>\n",
              "      <td>investopedia</td>\n",
              "      <td>1</td>\n",
              "      <td>37.98</td>\n",
              "      <td>16.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.79</td>\n",
              "      <td>18.5</td>\n",
              "      <td>9.10</td>\n",
              "      <td>20.500000</td>\n",
              "      <td>16.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>UCLA Anderson School of Management</td>\n",
              "      <td>UCLA Anderson School of Management is the grad...</td>\n",
              "      <td>investopedia</td>\n",
              "      <td>1</td>\n",
              "      <td>41.70</td>\n",
              "      <td>12.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.30</td>\n",
              "      <td>13.8</td>\n",
              "      <td>9.94</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>16.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>Unemployment</td>\n",
              "      <td>@1@ In economic terms,  involuntary unemployme...</td>\n",
              "      <td>sam</td>\n",
              "      <td>1</td>\n",
              "      <td>15.65</td>\n",
              "      <td>18.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.28</td>\n",
              "      <td>16.6</td>\n",
              "      <td>11.70</td>\n",
              "      <td>20.500000</td>\n",
              "      <td>16.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>Pro Forma Invoice</td>\n",
              "      <td>A pro forma invoice is a preliminary bill of s...</td>\n",
              "      <td>investopedia</td>\n",
              "      <td>1</td>\n",
              "      <td>58.62</td>\n",
              "      <td>10.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.60</td>\n",
              "      <td>12.9</td>\n",
              "      <td>10.69</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>12.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>full-payout lease</td>\n",
              "      <td>financial lease.</td>\n",
              "      <td>prin</td>\n",
              "      <td>0</td>\n",
              "      <td>35.61</td>\n",
              "      <td>8.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.00</td>\n",
              "      <td>14.9</td>\n",
              "      <td>19.53</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.80</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows Ã— 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45f2f8d2-7660-4a7c-bc77-54640eaaf9fe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45f2f8d2-7660-4a7c-bc77-54640eaaf9fe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45f2f8d2-7660-4a7c-bc77-54640eaaf9fe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#quantos dados positivo e negativos?\n",
        "df.assigned_readability.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy90HFtf3Hzv",
        "outputId": "1d099de6-7d8c-4678-b281-2863b74fb9ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    874\n",
              "0    626\n",
              "Name: assigned_readability, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Acessar os definitionsitionss contidos nas celulas, sÃ³ substituir o nÃºmero da celula que deseja vizualizar\n",
        "celula = df.loc[0, 'definitions']\n",
        "\n",
        "# Imprimir o conteÃºdo da cÃ©lula\n",
        "print(celula)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNLlKhMh35qO",
        "outputId": "82af0036-5b65-4ecf-f507-4b6b54b1fed0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A low/no documentation loan allows a potential borrower to apply for a mortgage while providing little or no information regarding their employment, income, or assets. Regulation of these loans has evolved significantly since 2008, but they remain an option for some borrowers in nontraditional financial situations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pre-processamento do definitions (stop words, misnusculas, caracteres especiais, stemizaÃ§Ã£o e tokenizaÃ§Ã£o)"
      ],
      "metadata": {
        "id": "TwiiGHcVccX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P7uAxFxvTPV",
        "outputId": "76a907ed-64ac-48f8-d189-015c3f9c6386"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes"
      ],
      "metadata": {
        "id": "FcplM6PyesNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Dividir o DataFrame em dados de treinamento e teste\n",
        "X = df['definitions']\n",
        "y = df['assigned_readability']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preencher valores nulos com uma string vazia\n",
        "imputer = SimpleImputer(strategy='constant', fill_value='')\n",
        "X_train = pd.DataFrame(X_train, columns=['definitions'])\n",
        "X_test = pd.DataFrame(X_test, columns=['definitions'])\n",
        "X_train['definitions'] = imputer.fit_transform(X_train[['definitions']])\n",
        "X_test['definitions'] = imputer.transform(X_test[['definitions']])\n",
        "\n",
        "# PrÃ©-processamento dos dados de definitions\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train['definitions'])\n",
        "X_test = vectorizer.transform(X_test['definitions'])\n",
        "\n",
        "# Inicializar os classificadores\n",
        "mnb = MultinomialNB()\n",
        "gnb = GaussianNB()\n",
        "bnb = BernoulliNB()\n",
        "\n",
        "# Realizar validaÃ§Ã£o cruzada nos classificadores\n",
        "cv_scores_mnb = cross_val_score(mnb, X_train, y_train, cv=5)\n",
        "cv_scores_gnb = cross_val_score(gnb, X_train.toarray(), y_train, cv=5)\n",
        "cv_scores_bnb = cross_val_score(bnb, X_train, y_train, cv=5)\n",
        "\n",
        "# Treinar os classificadores nos dados de treinamento completos\n",
        "mnb.fit(X_train, y_train)\n",
        "gnb.fit(X_train.toarray(), y_train)\n",
        "bnb.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsÃµes nos dados de teste\n",
        "y_pred_mnb = mnb.predict(X_test)\n",
        "y_pred_gnb = gnb.predict(X_test.toarray())\n",
        "y_pred_bnb = bnb.predict(X_test)\n"
      ],
      "metadata": {
        "id": "SPwxAcFYeDXc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular a matriz de confusÃ£o\n",
        "confusion_mnb = confusion_matrix(y_test, y_pred_mnb)\n",
        "print(\"confusion_mnb\", confusion_mnb)\n",
        "confusion_gnb = confusion_matrix(y_test, y_pred_gnb)\n",
        "print(\"confusion_gnb\", confusion_gnb)\n",
        "confusion_bnb = confusion_matrix(y_test, y_pred_bnb)\n",
        "print(\"confusion_bnb\", confusion_bnb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7kUc7UYv4lU",
        "outputId": "6c91c796-4dc1-400f-a7d9-a4962741a630"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion_mnb [[ 97  32]\n",
            " [ 12 159]]\n",
            "confusion_gnb [[ 75  54]\n",
            " [ 22 149]]\n",
            "confusion_bnb [[121   8]\n",
            " [ 34 137]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliar o desempenho dos classificadores com a mÃ©trica de acurÃ¡cia\n",
        "accuracy_mnb = accuracy_score(y_test, y_pred_mnb)\n",
        "print(\"accuracy_mnb\", accuracy_mnb)\n",
        "accuracy_gnb = accuracy_score(y_test, y_pred_gnb)\n",
        "print(\"accuracy_gnb\", accuracy_gnb)\n",
        "accuracy_bnb = accuracy_score(y_test, y_pred_bnb)\n",
        "print(\"accuracy_bnb\", accuracy_bnb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBCe0CFGvrsF",
        "outputId": "2eb06511-8475-41cf-a369-334ce23b4ab6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_mnb 0.8533333333333334\n",
            "accuracy_gnb 0.7466666666666667\n",
            "accuracy_bnb 0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suporte Vector Machine"
      ],
      "metadata": {
        "id": "tq7eIu4aeQ0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Dividir o DataFrame em dados de treinamento e teste\n",
        "X = df['definitions']\n",
        "y = df['assigned_readability']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# PrÃ©-processamento dos dados de definitions\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)\n",
        "\n",
        "# Inicializar o classificador SVM\n",
        "svm = SVC()\n",
        "\n",
        "# Treinar o classificador SVM\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsÃµes nos dados de teste\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "\n",
        "# Gerar a matriz de confusÃ£o\n",
        "confusion_mtx_svm = confusion_matrix(y_test, y_pred_svm)\n",
        "\n",
        "print(\"Matriz de ConfusÃ£o - SVM:\")\n",
        "print(confusion_mtx_svm)\n",
        "\n",
        "# Calcular a acurÃ¡cia do modelo SVM\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "\n",
        "print(\"AcurÃ¡cia - SVM:\", accuracy_svm)\n"
      ],
      "metadata": {
        "id": "eW1HYInhezbj",
        "outputId": "8fa94e66-223b-4341-ba58-80c39dded4a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de ConfusÃ£o - SVM:\n",
            "[[107  22]\n",
            " [ 27 144]]\n",
            "AcurÃ¡cia - SVM: 0.8366666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Redes Neurais\n",
        "\n",
        "Perceptron de MÃºltiplas Camadas (Multilayer Perceptron, MLP). O MLP Ã© uma arquitetura de rede neural artificial que consiste em vÃ¡rias camadas de neurÃ´nios, incluindo uma camada de entrada, uma ou mais camadas ocultas e uma camada de saÃ­da. Cada neurÃ´nio em uma camada estÃ¡ conectado a todos os neurÃ´nios na camada seguinte, formando uma rede densamente conectada."
      ],
      "metadata": {
        "id": "lhqBzsyQe9DX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Dividir o DataFrame em dados de treinamento e teste\n",
        "X = df['definitions']\n",
        "y = df['assigned_readability']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# PrÃ©-processamento dos dados de definitions\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)\n",
        "\n",
        "# Inicializar o classificador MLP\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), random_state=42)\n",
        "\n",
        "# Treinar o classificador MLP\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsÃµes nos dados de teste\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "\n",
        "# Gerar a matriz de confusÃ£o\n",
        "confusion_mtx_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
        "\n",
        "print(\"Matriz de ConfusÃ£o - MLP:\")\n",
        "print(confusion_mtx_mlp)\n",
        "\n",
        "# Calcular a acurÃ¡cia do modelo MLP\n",
        "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
        "\n",
        "print(\"AcurÃ¡cia - MLP:\", accuracy_mlp)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeSoVTuwe-4D",
        "outputId": "8e082a85-55d3-4a2b-9ff7-98e3eb3d5f6a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de ConfusÃ£o - MLP:\n",
            "[[109  20]\n",
            " [ 30 141]]\n",
            "AcurÃ¡cia - MLP: 0.8333333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recurrent Neural Network (RNN): RNNs, em particular, as variantes como Long Short-Term Memory (LSTM) ou Gated Recurrent Unit (GRU), sÃ£o amplamente utilizadas em anÃ¡lise textual. Essas arquiteturas sÃ£o capazes de capturar dependÃªncias de contexto e sequenciais em texto, tornando-as adequadas para tarefas como classificaÃ§Ã£o de sentimento, geraÃ§Ã£o de texto ou traduÃ§Ã£o automÃ¡tica."
      ],
      "metadata": {
        "id": "cx6QEt2zQ9pF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import tensorflow as tf\n",
        "\n",
        "# Dividir o DataFrame em dados de treinamento e teste\n",
        "X = df['definitions']\n",
        "y = df['assigned_readability']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# PrÃ©-processamento dos dados de definitions\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train).toarray()\n",
        "X_test = vectorizer.transform(X_test).toarray()\n",
        "\n",
        "# Definir a arquitetura da RNN\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(vectorizer.vocabulary_), output_dim=100, input_length=X_train.shape[1]),\n",
        "    tf.keras.layers.SimpleRNN(units=64),\n",
        "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Treinar a RNN\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Fazer previsÃµes nos dados de teste\n",
        "y_pred_rnn = model.predict(X_test)\n",
        "y_pred_rnn = (y_pred_rnn > 0.5).astype(int)\n",
        "\n",
        "# Gerar a matriz de confusÃ£o\n",
        "confusion_mtx_rnn = confusion_matrix(y_test, y_pred_rnn)\n",
        "\n",
        "print(\"Matriz de ConfusÃ£o - RNN:\")\n",
        "print(confusion_mtx_rnn)\n",
        "\n",
        "# Calcular a acurÃ¡cia do modelo RNN\n",
        "accuracy_rnn = accuracy_score(y_test, y_pred_rnn)\n",
        "\n",
        "print(\"AcurÃ¡cia - RNN:\", accuracy_rnn)\n"
      ],
      "metadata": {
        "id": "UP6yvBDxQ6U2",
        "outputId": "758b51a2-462d-4ba0-c23f-33e83ecbe3d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 5/38 [==>...........................] - ETA: 3:47 - loss: 0.6711 - accuracy: 0.6438"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional Neural Network (CNN): Embora inicialmente desenvolvidas para processamento de imagens, as CNNs tambÃ©m podem ser aplicadas a anÃ¡lise textual, especialmente em tarefas como classificaÃ§Ã£o de texto ou extraÃ§Ã£o de caracterÃ­sticas. As camadas convolucionais nas CNNs sÃ£o capazes de extrair informaÃ§Ãµes relevantes de n-gramas de palavras, capturando padrÃµes locais em textos."
      ],
      "metadata": {
        "id": "otOpT_NHRMl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import tensorflow as tf\n",
        "\n",
        "# Dividir o DataFrame em dados de treinamento e teste\n",
        "X = df['definitions']\n",
        "y = df['assigned_readability']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# PrÃ©-processamento dos dados de definitions\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train).toarray()\n",
        "X_test = vectorizer.transform(X_test).toarray()\n",
        "\n",
        "# Redimensionar os dados para a entrada da CNN (adicionar uma dimensÃ£o de canal)\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "X_test = np.expand_dims(X_test, axis=-1)\n",
        "\n",
        "# Definir a arquitetura da CNN\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Treinar a CNN\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Fazer previsÃµes nos dados de teste\n",
        "y_pred_cnn = model.predict(X_test)\n",
        "y_pred_cnn = (y_pred_cnn > 0.5).astype(int)\n",
        "\n",
        "# Gerar a matriz de confusÃ£o\n",
        "confusion_mtx_cnn = confusion_matrix(y_test, y_pred_cnn)\n",
        "\n",
        "print(\"Matriz de ConfusÃ£o - CNN:\")\n",
        "print(confusion_mtx_cnn)\n",
        "\n",
        "# Calcular a acurÃ¡cia do modelo CNN\n",
        "accuracy_cnn = accuracy_score(y_test, y_pred_cnn)\n",
        "\n",
        "print(\"AcurÃ¡cia - CNN:\", accuracy_cnn)\n"
      ],
      "metadata": {
        "id": "o08iH2RlRP09"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}