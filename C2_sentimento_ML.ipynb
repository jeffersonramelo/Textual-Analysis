{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPOIW0ii0FBDy5MRS4rUHj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffersonramelo/Textual-Analysis/blob/main/C2_sentimento_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho do arquivo CSV\n",
        "caminho_arquivo = \"/content/C123_dataset sentimento rotulados.csv\"\n",
        "\n",
        "# Ler o arquivo CSV\n",
        "import pandas as pd\n",
        "df = pd.read_csv(caminho_arquivo, sep=\",\", encoding='latin-1')"
      ],
      "metadata": {
        "id": "c2mDZfX7YWnV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vizualizar dados\n",
        "df.head()"
      ],
      "metadata": {
        "id": "wqgE3so93YYp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "270a7b58-0332-4ab2-b674-9fa028d95e71"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  sentimento_rotulado                                              texto  id\n",
              "0             neutral  According to Gran , the company has no plans t...   1\n",
              "1             neutral  Technopolis plans to develop in stages an area...   2\n",
              "2            negative  The international electronic industry company ...   3\n",
              "3            positive  With the new production plant the company woul...   4\n",
              "4            positive  According to the company 's updated strategy f...   5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97f1c7b9-fcd3-42c2-b20b-896ff9a6f133\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentimento_rotulado</th>\n",
              "      <th>texto</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>According to Gran , the company has no plans t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>According to the company 's updated strategy f...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97f1c7b9-fcd3-42c2-b20b-896ff9a6f133')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-97f1c7b9-fcd3-42c2-b20b-896ff9a6f133 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-97f1c7b9-fcd3-42c2-b20b-896ff9a6f133');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#quantos dados positivo e negativos?\n",
        "df.sentimento_rotulado.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy90HFtf3Hzv",
        "outputId": "cafb68c0-1196-47e4-920a-000a927ddf33"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral     2879\n",
              "positive    1363\n",
              "negative     604\n",
              "Name: sentimento_rotulado, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Acessar os textos contidos nas celulas, só substituir o número da celula que deseja vizualizar\n",
        "celula = df.loc[4, 'texto']\n",
        "\n",
        "# Imprimir o conteúdo da célula\n",
        "print(celula)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNLlKhMh35qO",
        "outputId": "47bc7e61-2cc6-4243-a926-de4bd3eb0423"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "According to the company 's updated strategy for the years 2009-2012 , Basware targets a long-term net sales growth in the range of 20 % -40 % with an operating profit margin of 10 % -20 % of net sales .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pre-processamento do texto (stop words, misnusculas, caracteres especiais, stemização e tokenização)"
      ],
      "metadata": {
        "id": "TwiiGHcVccX9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "baixar stop words do pacote NLTK, tem disponibilidade de vários idiomas, no português pode seguir o comando: stopwords_pt = stopwords.words('portuguese')"
      ],
      "metadata": {
        "id": "6TBSdYZsyAYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stopwords_en = stopwords.words('english')"
      ],
      "metadata": {
        "id": "ISb-hKm8Wy3K",
        "outputId": "ab55c275-4df5-4f7e-e570-8ebe53439363",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_en"
      ],
      "metadata": {
        "id": "QnUjVFYaW0cP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d154687-9181-4eb6-8bd0-468dd97c556a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Converter para minúsculas\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remover números\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Remover sinais de pontuação e caracteres especiais\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # Remover stopwords\n",
        "    stopwords_en = stopwords.words('english')\n",
        "    text = ' '.join([word for word in text.split() if word not in stopwords_en])\n",
        "\n",
        "    return text\n",
        "\n",
        "df['texto'] = df['texto'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "OkyVV5R3W3Ln"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Criar uma instância do stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Função para realizar a stemização das palavras em um texto\n",
        "def stem_text(text):\n",
        "    # Tokenizar o texto em palavras\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Aplicar a stemização em cada palavra\n",
        "    stemmed_words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "    # Juntar as palavras novamente em um texto\n",
        "    stemmed_text = ' '.join(stemmed_words)\n",
        "\n",
        "    return stemmed_text\n",
        "\n",
        "# Aplicar a função de stemização na coluna \"texto\" do DataFrame\n",
        "df['texto'] = df['texto'].apply(stem_text)\n"
      ],
      "metadata": {
        "id": "OuWSuW_hW8zI",
        "outputId": "e42eebb7-476c-46a9-b418-3ed1f58867f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "OkBKWa4-ZMVG",
        "outputId": "f0c7d2e3-18ad-40d2-e7e1-b1a1d9c202ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sentimento_rotulado                                              texto  \\\n",
              "0                neutral  accord gran compani plan move product russia a...   \n",
              "1                neutral  technopoli plan develop stage area less squar ...   \n",
              "2               negative  intern electron industri compani elcoteq laid ...   \n",
              "3               positive  new product plant compani would increas capac ...   \n",
              "4               positive  accord compani updat strategi year baswar targ...   \n",
              "...                  ...                                                ...   \n",
              "4841            negative  london marketwatch share price end lower londo...   \n",
              "4842             neutral  rinkuskiai beer sale fell per cent million lit...   \n",
              "4843            negative  oper profit fell eur mn eur mn includ vessel s...   \n",
              "4844            negative  net sale paper segment decreas eur mn second q...   \n",
              "4845            negative  sale finland decreas januari sale outsid finla...   \n",
              "\n",
              "        id  \n",
              "0        1  \n",
              "1        2  \n",
              "2        3  \n",
              "3        4  \n",
              "4        5  \n",
              "...    ...  \n",
              "4841  4842  \n",
              "4842  4843  \n",
              "4843  4844  \n",
              "4844  4845  \n",
              "4845  4846  \n",
              "\n",
              "[4846 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5b5c787-8052-4d65-b4b2-f57bb41fe4dc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentimento_rotulado</th>\n",
              "      <th>texto</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>accord gran compani plan move product russia a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>technopoli plan develop stage area less squar ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>intern electron industri compani elcoteq laid ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>new product plant compani would increas capac ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>accord compani updat strategi year baswar targ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4841</th>\n",
              "      <td>negative</td>\n",
              "      <td>london marketwatch share price end lower londo...</td>\n",
              "      <td>4842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4842</th>\n",
              "      <td>neutral</td>\n",
              "      <td>rinkuskiai beer sale fell per cent million lit...</td>\n",
              "      <td>4843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4843</th>\n",
              "      <td>negative</td>\n",
              "      <td>oper profit fell eur mn eur mn includ vessel s...</td>\n",
              "      <td>4844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4844</th>\n",
              "      <td>negative</td>\n",
              "      <td>net sale paper segment decreas eur mn second q...</td>\n",
              "      <td>4845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4845</th>\n",
              "      <td>negative</td>\n",
              "      <td>sale finland decreas januari sale outsid finla...</td>\n",
              "      <td>4846</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4846 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5b5c787-8052-4d65-b4b2-f57bb41fe4dc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d5b5c787-8052-4d65-b4b2-f57bb41fe4dc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d5b5c787-8052-4d65-b4b2-f57bb41fe4dc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes"
      ],
      "metadata": {
        "id": "FcplM6PyesNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn"
      ],
      "metadata": {
        "id": "sGgVIaKT1aGu",
        "outputId": "14f36d0c-a87a-43f7-8ec0-a6a714c6e95d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "metadata": {
        "id": "QLRNWQSe2CZM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir o DataFrame em dados de treinamento e teste\n",
        "X = df['texto']\n",
        "y = df['sentimento_rotulado']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preencher valores nulos com uma string vazia\n",
        "imputer = SimpleImputer(strategy='constant', fill_value='')\n",
        "X_train = pd.DataFrame(X_train, columns=['texto'])\n",
        "X_test = pd.DataFrame(X_test, columns=['texto'])\n",
        "X_train['texto'] = imputer.fit_transform(X_train[['texto']])\n",
        "X_test['texto'] = imputer.transform(X_test[['texto']])\n",
        "\n",
        "# Pré-processamento dos dados de texto\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train['texto']) #A função fit_transform é aplicada aos dados de TREINAMENTO para construir o VOCABULÁRIO e codificar o texto em forma de matriz.\n",
        "X_test = vectorizer.transform(X_test['texto']) #A função transform é aplicada aos dados de TESTE para codificá-los usando o mesmo VOCABULÁRIO criado nos dados de treinamento.\n",
        "\n",
        "# Inicializar os classificadores\n",
        "mnb = MultinomialNB() # utilizado para classificação de texto em que a frequência das palavras é relevante. Calcula as probabilidades condicionais com base nas frequências das palavras nas diferentes classes.\n",
        "gnb = GaussianNB() # calcula as probabilidades condicionais usando as médias e desvios padrão das classes.É usado em problemas de classificação onde os atributos são contínuos, como classificação de dados numéricos, detecção de anomalias ou reconhecimento de padrões\n",
        "bnb = BernoulliNB() #usado para classificação binária. Ele trata apenas da presença ou ausência das palavras em um documento, não levando em consideração a frequência ou contagem das palavras.\n",
        "\n",
        "\n",
        "# Realizar validação cruzada nos classificadores\n",
        "cv_scores_mnb = cross_val_score(mnb, X_train, y_train, cv=5)\n",
        "cv_scores_gnb = cross_val_score(gnb, X_train.toarray(), y_train, cv=5)\n",
        "cv_scores_bnb = cross_val_score(bnb, X_train, y_train, cv=5)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Treinar os classificadores nos dados de treinamento completos (usa o método fit.)\n",
        "mnb.fit(X_train, y_train)\n",
        "gnb.fit(X_train.toarray(), y_train)\n",
        "bnb.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsões nos dados de teste\n",
        "y_pred_mnb = mnb.predict(X_test)\n",
        "y_pred_gnb = gnb.predict(X_test.toarray())\n",
        "y_pred_bnb = bnb.predict(X_test)"
      ],
      "metadata": {
        "id": "HqbKOyknS5i0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular a matriz de confusão\n",
        "labels = [\"negative\", \"neutral\", \"positive\"]\n",
        "\n",
        "confusion_mnb = confusion_matrix(y_test, y_pred_mnb, labels=labels)\n",
        "print(\"Matriz de Confusão - Multinomial Naive Bayes:\")\n",
        "print(pd.DataFrame(confusion_mnb, index=labels, columns=labels))\n",
        "print()\n",
        "\n",
        "confusion_gnb = confusion_matrix(y_test, y_pred_gnb, labels=labels)\n",
        "print(\"Matriz de Confusão - Gaussian Naive Bayes:\")\n",
        "print(pd.DataFrame(confusion_gnb, index=labels, columns=labels))\n",
        "print()\n",
        "\n",
        "confusion_bnb = confusion_matrix(y_test, y_pred_bnb, labels=labels)\n",
        "print(\"Matriz de Confusão - Bernoulli Naive Bayes:\")\n",
        "print(pd.DataFrame(confusion_bnb, index=labels, columns=labels))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4Km5FecTWdc",
        "outputId": "8b2e0c15-20a7-40b9-b29e-16b6733a00e9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Confusão - Multinomial Naive Bayes:\n",
            "          negative  neutral  positive\n",
            "negative        59       34        17\n",
            "neutral         14      489        68\n",
            "positive        18      124       147\n",
            "\n",
            "Matriz de Confusão - Gaussian Naive Bayes:\n",
            "          negative  neutral  positive\n",
            "negative        64       28        18\n",
            "neutral         82      305       184\n",
            "positive        72      107       110\n",
            "\n",
            "Matriz de Confusão - Bernoulli Naive Bayes:\n",
            "          negative  neutral  positive\n",
            "negative        16       55        39\n",
            "neutral          1      540        30\n",
            "positive         4      146       139\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular os indicadores de desempenho\n",
        "accuracy_mnb = accuracy_score(y_test, y_pred_mnb)\n",
        "precision_mnb = precision_score(y_test, y_pred_mnb, average='weighted')\n",
        "recall_mnb = recall_score(y_test, y_pred_mnb, average='weighted')\n",
        "f1_mnb = f1_score(y_test, y_pred_mnb, average='weighted')\n",
        "\n",
        "accuracy_gnb = accuracy_score(y_test, y_pred_gnb)\n",
        "precision_gnb = precision_score(y_test, y_pred_gnb, average='weighted')\n",
        "recall_gnb = recall_score(y_test, y_pred_gnb, average='weighted')\n",
        "f1_gnb = f1_score(y_test, y_pred_gnb, average='weighted')\n",
        "\n",
        "accuracy_bnb = accuracy_score(y_test, y_pred_bnb)\n",
        "precision_bnb = precision_score(y_test, y_pred_bnb, average='weighted')\n",
        "recall_bnb = recall_score(y_test, y_pred_bnb, average='weighted')\n",
        "f1_bnb = f1_score(y_test, y_pred_bnb, average='weighted')\n",
        "\n",
        "# Exibir os indicadores de desempenho\n",
        "print(\"Indicadores de Desempenho:\")\n",
        "df_results = pd.DataFrame({\n",
        "    'Modelo': ['Multinomial Naive Bayes', 'Gaussian Naive Bayes', 'Bernoulli Naive Bayes'],\n",
        "    'Acurácia': [accuracy_mnb, accuracy_gnb, accuracy_bnb],\n",
        "    'Precisão': [precision_mnb, precision_gnb, precision_bnb],\n",
        "    'Recall': [recall_mnb, recall_gnb, recall_bnb],\n",
        "    'F1-score': [f1_mnb, f1_gnb, f1_bnb]\n",
        "})\n",
        "print(df_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2YtR_SATbMV",
        "outputId": "326e5229-feb9-4e4e-8bf9-4b4ec75f8dc6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indicadores de Desempenho:\n",
            "                    Modelo  Acurácia  Precisão    Recall  F1-score\n",
            "0  Multinomial Naive Bayes  0.716495  0.707211  0.716495  0.707368\n",
            "1     Gaussian Naive Bayes  0.493814  0.546383  0.493814  0.508492\n",
            "2    Bernoulli Naive Bayes  0.716495  0.714487  0.716495  0.678922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suporte Vector Machine: procura uma reta que melhor separa as classes"
      ],
      "metadata": {
        "id": "tq7eIu4aeQ0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Dividir o DataFrame em dados de treinamento e teste\n",
        "X = df['texto']\n",
        "y = df['sentimento_rotulado']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preencher valores nulos com uma string vazia\n",
        "imputer = SimpleImputer(strategy='constant', fill_value='')\n",
        "X_train = pd.DataFrame(X_train, columns=['texto'])\n",
        "X_test = pd.DataFrame(X_test, columns=['texto'])\n",
        "X_train['texto'] = imputer.fit_transform(X_train[['texto']])\n",
        "X_test['texto'] = imputer.transform(X_test[['texto']])\n",
        "\n",
        "# Pré-processamento dos dados de texto\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train['texto'])\n",
        "X_test = vectorizer.transform(X_test['texto'])\n",
        "\n",
        "# Inicializar o classificador SVM\n",
        "svm = SVC()\n",
        "\n",
        "# Realizar validação cruzada no classificador SVM\n",
        "cv_scores_svm = cross_val_score(svm, X_train, y_train, cv=5)\n",
        "\n",
        "# Treinar o classificador SVM nos dados de treinamento completos\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsões nos dados de teste\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "\n",
        "# Calcular a matriz de confusão\n",
        "labels = [\"negative\", \"neutral\", \"positive\"]\n",
        "confusion_svm = confusion_matrix(y_test, y_pred_svm, labels=labels)\n",
        "print(\"Matriz de Confusão - SVM:\")\n",
        "print(pd.DataFrame(confusion_svm, index=labels, columns=labels))\n",
        "print()\n",
        "\n",
        "# Calcular os indicadores de desempenho\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "precision_svm = precision_score(y_test, y_pred_svm, average='weighted')\n",
        "recall_svm = recall_score(y_test, y_pred_svm, average='weighted')\n",
        "f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
        "\n",
        "# Exibir os indicadores de desempenho\n",
        "print(\"Indicadores de Desempenho:\")\n",
        "df_results_svm = pd.DataFrame({\n",
        "    'Modelo': ['SVM'],\n",
        "    'Acurácia': [accuracy_svm],\n",
        "    'Precisão': [precision_svm],\n",
        "    'Recall': [recall_svm],\n",
        "    'F1-score': [f1_svm]\n",
        "})\n",
        "print(df_results_svm)\n"
      ],
      "metadata": {
        "id": "OVfWYV1HUUcU",
        "outputId": "8b247366-7076-42d7-b0ec-6c4f10fc9472",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Confusão - SVM:\n",
            "          negative  neutral  positive\n",
            "negative        39       56        15\n",
            "neutral          3      557        11\n",
            "positive        14      169       106\n",
            "\n",
            "Indicadores de Desempenho:\n",
            "  Modelo  Acurácia  Precisão    Recall  F1-score\n",
            "0    SVM  0.723711  0.737518  0.723711  0.687992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Redes Neurais\n",
        "\n",
        "A rede neural utilizada no exemplo é um Perceptron de Múltiplas Camadas (Multilayer Perceptron, MLP). O MLP é uma arquitetura de rede neural artificial que consiste em várias camadas de neurônios, incluindo uma camada de entrada, uma ou mais camadas ocultas e uma camada de saída. Cada neurônio em uma camada está conectado a todos os neurônios na camada seguinte, formando uma rede densamente conectada.\n",
        "\n",
        " Por padrão a função de ativação ReLU é usada no MLPClassifier do scikit-learn."
      ],
      "metadata": {
        "id": "lhqBzsyQe9DX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Dividir o DataFrame em dados de treinamento e teste\n",
        "X = df['texto']\n",
        "y = df['sentimento_rotulado']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Pré-processamento dos dados de texto\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)\n",
        "\n",
        "# Inicializar o classificador MLP\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), random_state=42) #Aqui, estamos criando um MLP com uma camada oculta de 100 neurônios.\n",
        "\n",
        "# Treinar o classificador MLP\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsões nos dados de teste\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "\n",
        "# Gerar a matriz de confusão\n",
        "labels = [\"negative\", \"neutral\", \"positive\"]\n",
        "confusion_mtx_mlp = confusion_matrix(y_test, y_pred_mlp, labels=labels)\n",
        "\n",
        "print(\"Matriz de Confusão - MLP:\")\n",
        "print(pd.DataFrame(confusion_mtx_mlp, index=labels, columns=labels))\n",
        "\n",
        "# Calcular os indicadores de desempenho\n",
        "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
        "precision_mlp = precision_score(y_test, y_pred_mlp, average=None, labels=labels)\n",
        "recall_mlp = recall_score(y_test, y_pred_mlp, average=None, labels=labels)\n",
        "f1_mlp = f1_score(y_test, y_pred_mlp, average=None, labels=labels)\n",
        "\n",
        "print(\"Acurácia - MLP:\", accuracy_mlp)\n",
        "print(\"Precisão - MLP:\", precision_mlp)\n",
        "print(\"Recall - MLP:\", recall_mlp)\n",
        "print(\"F1-score - MLP:\", f1_mlp)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeSoVTuwe-4D",
        "outputId": "47f27852-7d2f-47ce-e2b4-38af3439a9a5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Confusão - MLP:\n",
            "          negative  neutral  positive\n",
            "negative        61       30        19\n",
            "neutral         27      460        84\n",
            "positive        16      109       164\n",
            "Acurácia - MLP: 0.7061855670103093\n",
            "Precisão - MLP: [0.58653846 0.76794658 0.61423221]\n",
            "Recall - MLP: [0.55454545 0.8056042  0.56747405]\n",
            "F1-score - MLP: [0.57009346 0.78632479 0.58992806]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "rede neurais com mais camadas ocultas"
      ],
      "metadata": {
        "id": "Sgrh9WjtC4ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Dividir o DataFrame em dados de treinamento e teste\n",
        "X = df['texto']\n",
        "y = df['sentimento_rotulado']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Pré-processamento dos dados de texto\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)\n",
        "\n",
        "# Inicializar o classificador MLP\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100, 100), random_state=42) # indicaria duas camadas ocultas, uma com 100 neurônios e outra com 100 neurônios\n",
        "\n",
        "# Treinar o classificador MLP\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsões nos dados de teste\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "\n",
        "# Gerar a matriz de confusão\n",
        "labels = [\"negative\", \"neutral\", \"positive\"]\n",
        "confusion_mtx_mlp = confusion_matrix(y_test, y_pred_mlp, labels=labels)\n",
        "\n",
        "print(\"Matriz de Confusão - MLP:\")\n",
        "print(pd.DataFrame(confusion_mtx_mlp, index=labels, columns=labels))\n",
        "\n",
        "# Calcular os indicadores de desempenho\n",
        "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
        "precision_mlp = precision_score(y_test, y_pred_mlp, average=None, labels=labels)\n",
        "recall_mlp = recall_score(y_test, y_pred_mlp, average=None, labels=labels)\n",
        "f1_mlp = f1_score(y_test, y_pred_mlp, average=None, labels=labels)\n",
        "\n",
        "print(\"Acurácia - MLP:\", accuracy_mlp)\n",
        "print(\"Precisão - MLP:\", precision_mlp)\n",
        "print(\"Recall - MLP:\", recall_mlp)\n",
        "print(\"F1-score - MLP:\", f1_mlp)\n"
      ],
      "metadata": {
        "id": "v-CHalD3C23F",
        "outputId": "2c0d88e5-3c4a-4da3-841e-ed88adda61b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Confusão - MLP:\n",
            "          negative  neutral  positive\n",
            "negative        58       34        18\n",
            "neutral         18      471        82\n",
            "positive        14      112       163\n",
            "Acurácia - MLP: 0.7134020618556701\n",
            "Precisão - MLP: [0.64444444 0.76337115 0.61977186]\n",
            "Recall - MLP: [0.52727273 0.82486865 0.56401384]\n",
            "F1-score - MLP: [0.58       0.79292929 0.59057971]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testar as funções de ativação das camadas ocultas {'tanh', 'relu', 'logistic:'}\n",
        "\n"
      ],
      "metadata": {
        "id": "f8AMZ4ONIHXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Dividir o DataFrame em dados de treinamento e teste\n",
        "X = df['texto']\n",
        "y = df['sentimento_rotulado']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Pré-processamento dos dados de texto\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)\n",
        "\n",
        "# Inicializar o classificador MLP\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100, 100), activation='logistic', random_state=42) #a função ReLU é a função de ativação padrão utilizada no MLPClassifier, no caso estamos utilizando a função tanh\n",
        "\n",
        "# Treinar o classificador MLP\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsões nos dados de teste\n",
        "y_pred_mlp = mlp.predict(X_test)\n",
        "\n",
        "# Gerar a matriz de confusão\n",
        "labels = [\"negative\", \"neutral\", \"positive\"]\n",
        "confusion_mtx_mlp = confusion_matrix(y_test, y_pred_mlp, labels=labels)\n",
        "\n",
        "print(\"Matriz de Confusão - MLP:\")\n",
        "print(pd.DataFrame(confusion_mtx_mlp, index=labels, columns=labels))\n",
        "\n",
        "# Calcular os indicadores de desempenho\n",
        "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
        "precision_mlp = precision_score(y_test, y_pred_mlp, average=None, labels=labels)\n",
        "recall_mlp = recall_score(y_test, y_pred_mlp, average=None, labels=labels)\n",
        "f1_mlp = f1_score(y_test, y_pred_mlp, average=None, labels=labels)\n",
        "\n",
        "print(\"Acurácia - MLP:\", accuracy_mlp)\n",
        "print(\"Precisão - MLP:\", precision_mlp)\n",
        "print(\"Recall - MLP:\", recall_mlp)\n",
        "print(\"F1-score - MLP:\", f1_mlp)\n"
      ],
      "metadata": {
        "id": "gJh4vBQwIFkS",
        "outputId": "3c935bb5-b2d8-410d-e64a-a42dfa9b43c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Confusão - MLP:\n",
            "          negative  neutral  positive\n",
            "negative        58       33        19\n",
            "neutral         29      447        95\n",
            "positive        16      109       164\n",
            "Acurácia - MLP: 0.6896907216494845\n",
            "Precisão - MLP: [0.5631068  0.75891341 0.58992806]\n",
            "Recall - MLP: [0.52727273 0.78283713 0.56747405]\n",
            "F1-score - MLP: [0.54460094 0.77068966 0.57848325]\n"
          ]
        }
      ]
    }
  ]
}